---
permalink: /
title: "About"
layout: archive
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Welcome! I am a final-year PhD candidate in [Computer Science](https://www.khoury.northeastern.edu/) at [Northeastern University](https://www.northeastern.edu/), conducting research with [Malihe Alikhani](https://www.malihealikhani.com/). I am passionate about using NLP tools for good, and my research focuses on developing responsible and fair AI tools using insights from linguistics and social sciences. I have published at venues including ACL, NAACL, EACL, SIGDIAL, COLING, and COGSCI, and won a [best paper award](https://www.sci.pitt.edu/news/sci-graduate-students-faculty-member-win-best-paper-award-uai-2022) for our [work](https://proceedings.mlr.press/v180/sicilia22a/sicilia22a.pdf) at UAI 2022. I was also part of a university team that placed [third](https://www.amazon.science/alexa-prize/taskbot-challenge/2022) in the Amazon [Alexa Prize Taskbot Competition](https://www.amazon.science/alexa-prize/taskbot-challenge)!

In my free time, I enjoy bouldering, playing the piano, singing (catch our concerts at [Cambridge Chamber Singers](https://cambridgechambersingers.org/)!), working out, and spending time outdoors!

**I'm currently on the job market**, so please feel free to reach out if you know of any opportunities that may be a good fit!

<span class="page__title"> Projects </span>
======

I believe that NLP is fundamentally interdisciplinary, and my research reflects this. I develop computational frameworks for understanding linguistic and social phenomena, and apply these frameworks to develop fair and responsible AI systems. Therefore, most of my current or past projects fall into one or more of the following categories: <b>Discourse and Pragmatics</b>, <b>Computational Social Science</b>, and <b>Responsible and Accessible AI</b>. Here are some examples of current and past projects:

## Evaluating the impacts of sycophancy in LLMs using insights from behavioral economics

![Image](https://katherine-atwell.github.io/images/projects/sycophancy-fig.png){: style="float: left; margin-right: 1em;" width="200px"} Drawing from insights in behavioral economics and rational decision theory, we are exploring how to model the ways in which AI systems navigate uncertainty when introduced to new information. This information may include the user's opinion or involvement in a particular scenario, both of which have been shown to induce sycophancy (excessively flattering or ingratiating behavior) in LLMs. In this project, we study how sycophancy can impact LLMs' beliefs and uncertainty estimations given new information, and the extent to which LLMs are Bayesian-rational when sycophancy is induced. <br>
<button name="button" class="btn btn--inverse" onclick="https://arxiv.org/abs/2508.16846">**ArXiv Preprint**</button>
<!-- [ArXiv Preprint](https://arxiv.org/abs/2508.16846) -->