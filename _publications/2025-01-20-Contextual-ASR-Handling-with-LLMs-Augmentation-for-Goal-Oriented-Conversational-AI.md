---
title: "Measuring Bias and Agreement in Large Language Model Presupposition Judgments"
collection: publications
permalink: /publication/2025-01-20-Contextual-ASR-Handling-with-LLMs-Augmentation-for-Goal-Oriented-Conversational-AI
date: 2025-07-27
venue: 'In the Proceedings of the 31st International Conference on Computational Linguistics: Industry Track'
venueinformal: 'COLING Industry Track 2025'
citation: 'Yuya Asano, Sabit Hassan, Paras Sharma, Anthony B. Sicilia, Katherine Atwell, Diane Litman, and Malihe Alikhani. 2025. Proceedings of the 31st International Conference on Computational Linguistics: Industry Track, Abu Dhabi. Association for Computational Linguistics.'
authors: 'Yuya Asano, Sabit Hassan, Paras Sharma, Anthony B. Sicilia, Katherine Atwell, Diane Litman, and Malihe Alikhani'
paperurl: https://aclanthology.org/anthology-files/pdf/coling/2025.coling-industry.32.pdf
abstract: "General-purpose automatic speech recognition (ASR) systems do not always perform well in goal-oriented dialogue. Existing ASR correction methods rely on prior user data or named entities. We extend correction to tasks that have no prior user data and exhibit linguistic flexibility such as lexical and syntactic variations. We propose a novel context augmentation with a large language model and a ranking strategy that incorporates contextual information from the dialogue states of a goal-oriented conversational AI and its tasks. Our method ranks (1) n-best ASR hypotheses by their lexical and semantic similarity with context and (2) context by phonetic correspondence with ASR hypotheses. Evaluated in home improvement and cooking domains with real-world users, our method improves recall and F1 of correction by 34% and 16%, respectively, while maintaining precision and false positive rate. Users rated .8-1 point (out of 5) higher when our correction method worked properly, with no decrease due to false positives."
---