---
title: "Appdia: A discourse-aware transformer-based style transfer model for offensive social media conversations"
collection: publications
permalink: /publication/2022-10-22-Appdia-A-discourse-aware-transformer-based-style-transfer-model-for-offensive-social-media-conversations
date: 2022-10-12
venue: 'In the proceedings of Proceedings of the 29th International Conference on Computational Linguistics'
citation: ' Katherine Atwell,  Sabit Hassan,  Malihe Alikhani, &quot;Appdia: A discourse-aware transformer-based style transfer model for offensive social media conversations.&quot; In the proceedings of Proceedings of the 29th International Conference on Computational Linguistics, 2022.'
venueinformal: 'COLING 2022'
paperurl: 'https://aclanthology.org/anthology-files/pdf/coling/2022.coling-1.530.pdf'
authors: 'Katherine Atwell, Sabit Hassan, and Malihe Alikhani'
abstract: "Using style-transfer models to reduce offensiveness of social media comments can help foster a more inclusive environment. However, there are no sizable datasets that contain offensive texts and their inoffensive counterparts, and fine-tuning pretrained models with limited labeled data can lead to the loss of original meaning in the style-transferred text. To address this issue, we provide two major contributions. First, we release the first publicly-available, parallel corpus of offensive Reddit comments and their style-transferred counterparts annotated by expert sociolinguists. Then, we introduce the first discourse-aware style-transfer models that can effectively reduce offensiveness in Reddit text while preserving the meaning of the original text. These models are the first to examine inferential links between the comment and the text it is replying to when transferring the style of offensive Reddit text. We propose two different methods of integrating discourse relations with pretrained transformer models and evaluate them on our dataset of offensive comments from Reddit and their inoffensive counterparts. Improvements over the baseline with respect to both automatic metrics and human evaluation indicate that our discourse-aware models are better at preserving meaning in style-transferred text when compared to the state-of-the-art discourse-agnostic models."
---
